{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac164a57-296f-47c1-aff1-ef496a66094d",
   "metadata": {},
   "source": [
    "# EASY OCR\n",
    "## Install\n",
    "```bash\n",
    "pip install easyocr\n",
    "```\n",
    "## demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0faf24f6-2ed9-4c00-aea8-1c4d682955e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56d2771d-c78a-4386-9fdf-7c9059189527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "reader = easyocr.Reader(['ch_sim','en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c334d44-897a-4080-a87d-964c86bcbdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 52.4 s\n",
      "Wall time: 7.18 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[([[40, 34], [284, 34], [284, 66], [40, 66]],\n",
       "  '1) Query-based RAG',\n",
       "  0.8665399543464708),\n",
       " ([[36, 89], [1197, 89], [1197, 127], [36, 127]],\n",
       "  '基于查询的RA6也称为提示增强。它将用户的查询与检索过程中从文件中获取的信息直接整合到语言模型输入的初始',\n",
       "  0.6445633264923623),\n",
       " ([[38, 137], [1196, 137], [1196, 170], [38, 170]],\n",
       "  '阶段。这种模式是RA6应用中广泛采用的方法。一旦检索到文档。它们的内容就会与用户的原始查询合并。从而创建',\n",
       "  0.5346363470958714),\n",
       " ([[59, 181], [911, 181], [911, 217], [59, 217]],\n",
       "  '个组合输入序列。这一增强序列随后被输入到预先训练好的语言模型中,以生成回复。',\n",
       "  0.6631744105065582),\n",
       " ([[38, 244], [66, 244], [66, 272], [38, 272]], '2)', 0.9986936134757679),\n",
       " ([[74, 244], [464, 244], [464, 274], [74, 274]],\n",
       "  'Latent Representation-based RAG',\n",
       "  0.7186558196823989),\n",
       " ([[37, 301], [343, 301], [343, 337], [37, 337]],\n",
       "  '在基于潜在表征的RA6框架中,',\n",
       "  0.35477296784906726),\n",
       " ([[353, 301], [1197, 301], [1197, 337], [353, 337]],\n",
       "  '生成模型与检索对象的潜在表征相互作用。从而提高模型的理解能力和生成内容的质',\n",
       "  0.5432405957286757),\n",
       " ([[40, 350], [70, 350], [70, 380], [40, 380]], '量', 0.9910269517043879),\n",
       " ([[39, 407], [271, 407], [271, 443], [39, 443]],\n",
       "  '3) Logit-based RAG',\n",
       "  0.9689810098710668),\n",
       " ([[38, 468], [1172, 468], [1172, 500], [38, 500]],\n",
       "  '在基于对数的RAG中,生成模型在解码过程中通过对数将检索信息结合起来。通常情况下。对数通过模型求和或组',\n",
       "  0.4198461081327144),\n",
       " ([[40, 514], [70, 514], [70, 546], [40, 546]], '合', 0.997587944982925),\n",
       " ([[84, 512], [324, 512], [324, 544], [84, 544]],\n",
       "  '以生逐步生成的概率。',\n",
       "  0.7730440269246807),\n",
       " ([[38, 574], [266, 574], [266, 606], [38, 606]],\n",
       "  '4) Speculative RAG',\n",
       "  0.8155951084671018),\n",
       " ([[37, 630], [456, 630], [456, 666], [37, 666]],\n",
       "  '投机性RAG寻找使用检索代替生成的机会;',\n",
       "  0.5062567379692637),\n",
       " ([[467, 631], [1205, 631], [1205, 667], [467, 667]],\n",
       "  '以节省资源和加快响应速度。例如, REST用检索取代了推测解码中的小模',\n",
       "  0.7884503036668209),\n",
       " ([[38, 678], [70, 678], [70, 710], [38, 710]], '型', 0.9986561286429243),\n",
       " ([[82, 677], [1144, 677], [1144, 710], [82, 710]],\n",
       "  '从而生成草稿。 GPTCache尝试通过建立语义缓存来存储LLM响应。从而解决使用LLMAPI时的高延迟问题。',\n",
       "  0.6016444537981477)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "result = reader.readtext('data/test_chinese.png')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43b86020-1f29-4105-b017-f7797928630c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.1 s\n",
      "Wall time: 4.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[([[48, 6], [88, 6], [88, 30], [48, 30]], 'I', 0.08367907184806089),\n",
       " ([[98, 6], [130, 6], [130, 30], [98, 30]], '8', 0.10397391412098855),\n",
       " ([[150, 18], [361, 18], [361, 80], [150, 80]], '登 机  牌', 0.3033306874304231),\n",
       " ([[417, 13], [662, 13], [662, 69], [417, 69]],\n",
       "  'BOARDING',\n",
       "  0.9938162510502586),\n",
       " ([[700, 9], [829, 9], [829, 65], [700, 65]], 'PASS', 0.9892305731773376),\n",
       " ([[62, 110], [108, 110], [108, 134], [62, 134]], '航班', 0.8667290454791475),\n",
       " ([[118, 108], [194, 108], [194, 132], [118, 132]],\n",
       "  'FLIGHT',\n",
       "  0.9848754060472928),\n",
       " ([[212, 106], [256, 106], [256, 132], [212, 132]], '日期', 0.9682042415054494),\n",
       " ([[268, 106], [318, 106], [318, 130], [268, 130]],\n",
       "  'DATE',\n",
       "  0.9870986938476562),\n",
       " ([[340, 104], [388, 104], [388, 132], [340, 132]], '舱位', 0.9678215845226255),\n",
       " ([[396, 102], [460, 102], [460, 126], [396, 126]],\n",
       "  'CLASS',\n",
       "  0.9862197465085734),\n",
       " ([[486, 102], [532, 102], [532, 126], [486, 126]], '序号', 0.9320828002071316),\n",
       " ([[542, 100], [648, 100], [648, 124], [542, 124]],\n",
       "  'SERIAL NO.',\n",
       "  0.7186576700613894),\n",
       " ([[674, 96], [740, 96], [740, 122], [674, 122]], '座位号', 0.991063350573132),\n",
       " ([[752, 96], [834, 96], [834, 120], [752, 120]],\n",
       "  'SEAT N0',\n",
       "  0.591198123336351),\n",
       " ([[82, 135], [216, 135], [216, 167], [82, 167]],\n",
       "  'W 2379',\n",
       "  0.19905307819131918),\n",
       " ([[234, 134], [332, 134], [332, 164], [234, 164]],\n",
       "  '03DEC',\n",
       "  0.2296784999521502),\n",
       " ([[404, 132], [434, 132], [434, 160], [404, 160]], '熨', 0.000224710460455386),\n",
       " ([[508, 130], [572, 130], [572, 158], [508, 158]], '035', 0.979935561322287),\n",
       " ([[65, 177], [130, 177], [130, 205], [65, 205]], '目的地', 0.8928722503776515),\n",
       " ([[143, 179], [169, 179], [169, 199], [143, 199]], 'T0', 0.9910904463945038),\n",
       " ([[340, 172], [408, 172], [408, 198], [340, 198]], '始发地', 0.9648149686991878),\n",
       " ([[418, 172], [470, 172], [470, 196], [418, 196]], 'FROM', 0.539820671081543),\n",
       " ([[488, 172], [554, 172], [554, 198], [488, 198]], '登机口', 0.9308806720119142),\n",
       " ([[567, 173], [615, 173], [615, 193], [567, 193]],\n",
       "  'GATE',\n",
       "  0.9962225556373596),\n",
       " ([[676, 168], [766, 168], [766, 194], [676, 194]],\n",
       "  '登机时间',\n",
       "  0.2601596713066101),\n",
       " ([[775, 169], [813, 169], [813, 189], [775, 189]], 'BDT', 0.982283661999874),\n",
       " ([[94, 204], [174, 204], [174, 230], [94, 230]], '福州', 0.06756196215187518),\n",
       " ([[333, 212], [478, 212], [478, 242], [333, 242]],\n",
       "  'TAIYUAN',\n",
       "  0.35269565854440227),\n",
       " ([[504, 212], [556, 212], [556, 238], [504, 238]],\n",
       "  '41',\n",
       "  0.010614995179550389),\n",
       " ([[87, 224], [206, 224], [206, 254], [87, 254]],\n",
       "  'FUZHOU',\n",
       "  0.8573581453553378),\n",
       " ([[342, 236], [484, 236], [484, 262], [342, 262]],\n",
       "  '身份识别10 N0。',\n",
       "  0.6147306844092337),\n",
       " ([[66, 248], [110, 248], [110, 274], [66, 274]], '姓名', 0.9767481592354383),\n",
       " ([[123, 249], [173, 249], [173, 269], [123, 269]],\n",
       "  'NAME',\n",
       "  0.9919445514678955),\n",
       " ([[73, 270], [266, 270], [266, 302], [73, 302]],\n",
       "  'ZIANGOI E',\n",
       "  0.40192738987121013),\n",
       " ([[460, 294], [584, 294], [584, 320], [460, 320]],\n",
       "  '票号 TKT NO。',\n",
       "  0.7416571578545699),\n",
       " ([[100, 310], [214, 310], [214, 340], [100, 340]], '张祺伟', 0.5181622964625447),\n",
       " ([[66, 338], [166, 338], [166, 369], [66, 369]],\n",
       "  '票价 FARE',\n",
       "  0.8471374351034233),\n",
       " ([[344, 344], [652, 344], [652, 374], [344, 374]],\n",
       "  'ETII 78136592384391',\n",
       "  0.20276720134780452),\n",
       " ([[97, 449], [346, 449], [346, 481], [97, 481]],\n",
       "  '登机口于起飞前10分钟关闭',\n",
       "  0.639078622780854),\n",
       " ([[358, 441], [834, 441], [834, 474], [358, 474]],\n",
       "  'GATES CLOSE 10 WINUTES BEFORE DEPARTURE TIlE',\n",
       "  0.2543452724357855)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "result = reader.readtext('data/00006737.jpg')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e1c5bc4-21ea-4c0e-a9d6-f0452a1e02aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 8s\n",
      "Wall time: 9.53 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[([[41, 29], [1003, 29], [1003, 67], [41, 67]],\n",
       "  'Embeddings LLMs generate numerical representations of data called  embeddings',\n",
       "  0.6241684503529916),\n",
       " ([[1016, 32], [1088, 32], [1088, 62], [1016, 62]],\n",
       "  'When',\n",
       "  0.9988475441932678),\n",
       " ([[37, 69], [1107, 69], [1107, 110], [37, 110]],\n",
       "  'filtering your data for relevance; Llamalndex will convert queries into embeddings, and your',\n",
       "  0.44736699160863935),\n",
       " ([[39, 111], [1023, 111], [1023, 151], [39, 151]],\n",
       "  'Vector store Will find data that is numerically similar to the embedding of your query。',\n",
       "  0.3936604516015874),\n",
       " ([[38, 208], [269, 208], [269, 256], [38, 256]],\n",
       "  'Querying Stage',\n",
       "  0.7605162298438248),\n",
       " ([[41, 284], [887, 284], [887, 321], [41, 321]],\n",
       "  'Retrievers: A retriever defines how to efficiently retrieve relevant context',\n",
       "  0.7218915674540571),\n",
       " ([[948, 286], [1122, 286], [1122, 318], [948, 318]],\n",
       "  'an index when',\n",
       "  0.7010803260804565),\n",
       " ([[40, 332], [108, 332], [108, 362], [40, 362]], 'given', 0.9973064084048787),\n",
       " ([[129, 327], [1069, 327], [1069, 366], [129, 366]],\n",
       "  'query. Your retrieval strategy is key to the relevancy of the data retrieved and the',\n",
       "  0.5145012749919049),\n",
       " ([[38, 369], [397, 369], [397, 407], [38, 407]],\n",
       "  \"efficiency with Which it's done。\",\n",
       "  0.6806147150863199),\n",
       " ([[42, 440], [1132, 440], [1132, 470], [42, 470]],\n",
       "  'Routers: A router determines Which retriever will be used to retrieve relevant context from the',\n",
       "  0.47975418612655646),\n",
       " ([[41, 479], [497, 479], [497, 519], [41, 519]],\n",
       "  'knowledge base. More specifically; the',\n",
       "  0.48698542080361457),\n",
       " ([[503, 479], [1163, 479], [1163, 521], [503, 521]],\n",
       "  'RouterRetriever class, is responsible for selecting one',\n",
       "  0.7010554593172419),\n",
       " ([[41, 531], [69, 531], [69, 551], [41, 551]], 'OI', 0.22079101853394384),\n",
       " ([[71, 523], [1177, 523], [1177, 561], [71, 561]],\n",
       "  'multiple candidate retrievers to execute a query. They use a selector to choose the best option',\n",
       "  0.593764848142139),\n",
       " ([[42, 567], [646, 567], [646, 600], [42, 600]],\n",
       "  'based on each candidates metadata and the query。',\n",
       "  0.6303014498015034),\n",
       " ([[42, 636], [1004, 636], [1004, 669], [42, 669]],\n",
       "  'Node Postprocessors: A node postprocessor takes in a set of retrieved nodes and',\n",
       "  0.5112789005943841),\n",
       " ([[38, 676], [655, 676], [655, 714], [38, 714]],\n",
       "  'transformations, filtering, or re-ranking logic to them',\n",
       "  0.6098911799153468),\n",
       " ([[40, 741], [1179, 741], [1179, 784], [40, 784]],\n",
       "  'Response Synthesizers: A response synthesizer generates a response from an LLM, using a user',\n",
       "  0.8294547621070693),\n",
       " ([[38, 787], [579, 787], [579, 825], [38, 825]],\n",
       "  'query and a given set of retrieved text chunks。',\n",
       "  0.8055260642727468),\n",
       " ([[38, 883], [347, 883], [347, 928], [38, 928]],\n",
       "  'Putting it all together',\n",
       "  0.8508314242103211),\n",
       " ([[887.1299778141514, 283.1289267866996],\n",
       "   [949.8414337268835, 291.0375788989588],\n",
       "   [945.8700221858486, 321.8710732133004],\n",
       "   [882.1585662731165, 313.9624211010412]],\n",
       "  'from',\n",
       "  0.9998177886009216),\n",
       " ([[1002.3447882227953, 638.3585340901495],\n",
       "   [1095.635583975624, 631.3319085288314],\n",
       "   [1096.6552117772048, 667.6414659098505],\n",
       "   [1003.3644160243759, 673.6680914711686]],\n",
       "  'applies',\n",
       "  0.9983885720295935)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "reader.readtext('data/test_english.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4452e404-dd13-4769-97f6-620e2c3dce7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
